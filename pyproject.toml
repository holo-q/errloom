[project]
name = "Errloom"
authors = [
    {name = "Nicolas Martel"},
]
version = "0.1.1"
description = "Errloom the a Swiss Army Knife of context engineering, reinforcement learning, and loom coding with LLMs."
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.11,<3.13"
keywords = ["reinforcement-learning", "llm", "rl", "grpo", "prompt engineering", "verifiable-environments", "multi-turn"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "torch>=2.6.0",
    "accelerate",
    "peft",
    "wandb",
    "rich",
    "trl>=0.17.0",
    "requests>=2.32.3",
    "openai>=1.81.0",
    "datasets>=3.6.0",
    "transformers",
    "testslide",
    "opensimplex",
    "opencv-python-headless",
    "msgspec",
    "asyncssh",
    "desktop_notifier",
    "prompt_toolkit",
    "aiofiles"
]

[project.optional-dependencies]
all = [
    "vllm>=0.8.5.post1",
    "liger-kernel>=0.5.10",
    "deepspeed",
    "ipykernel",
    "ipywidgets",
    "duckduckgo-search",
    "brave-search",
    "reasoning-gym",
    "smolagents>=1.15.0",
    "textarena",
    "nltk"
]

tests = [
    "testslide",
]

[project.scripts]
main = "errloom.main:run"
errl = "errloom.main:run"
vf-vllm = "errloom.inference.vllm_server:cli_main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    "twine>=6.1.0",  # For uploading to PyPI
]

[project.urls]
Homepage = "https://github.com/holo-q/errloom"
Documentation = "https://github.com/holo-q/errloom"
Repository = "https://github.com/holo-q/errloom.git"
Issues = "https://github.com/holo-q/errloom/issues"
